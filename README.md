# Simulaciones de Teor칤a de Juegos: Axelrod y M치s 游꿡

Este repositorio contiene simulaciones en Python de los experimentos cl치sicos de Robert Axelrod en teor칤a de juegos, junto con extensiones modernas que exploran herencia gen칠tica, orientaci칩n espacial y desviaciones basadas en inteligencia artificial (AI). Aqu칤 encontrar치s herramientas para entender c칩mo las estrategias cooperativas y competitivas emergen, evolucionan y se adaptan en entornos din치micos.

---

## 游닆 Or칤genes de la Teor칤a de Juegos

La **teor칤a de juegos** nace en el siglo XX como un marco matem치tico para analizar decisiones estrat칠gicas entre agentes racionales. Sus fundamentos se establecieron con los trabajos de **John von Neumann** y **Oskar Morgenstern** en *Theory of Games and Economic Behavior* (1944), y luego con las contribuciones de **John Nash** sobre equilibrios no cooperativos. Axelrod, en los a침os 80, revolucion칩 el campo al organizar torneos computacionales donde programas compet칤an en el *Dilema del Prisionero Iterado*, demostrando que estrategias simples como **Tit for Tat** (Toma y Daca) pod칤an fomentar cooperaci칩n incluso en entornos ego칤stas.

---

## 游빌 El Dilema del Prisionero: Cooperaci칩n vs. Traici칩n

### La Paradoja Cl치sica
En el **Dilema del Prisionero**, dos delincuentes son interrogados por separado:
- Si ambos **cooperan** (no delatan), reciben una pena leve.
- Si uno **traiciona** y el otro coopera, el traidor sale libre y el cooperador recibe m치xima pena.
- Si ambos traicionan, ambos reciben penas moderadas.

Aunque la cooperaci칩n genera el mejor resultado colectivo, el incentivo individual lleva a la traici칩n (equilibrio de Nash). Axelrod demostr칩 que, en interacciones repetidas, estrategias *reciprocantes* como **Tit for Tat** (iniciar cooperando y luego replicar la acci칩n previa del oponente) superan a las puramente ego칤stas. De forma que, comprendemos que la teoria de juegos tiene mucho que dictar en un entendimiento social a partir de perspectivas sistemicas.

### Cr칤tica al Modelo de Una Sola Interacci칩n
El dilema cl치sico asume una **칰nica interacci칩n**, lo que favorece la tracci칩n como estrategia dominante. Sin embargo, en la vida real (econom칤a, ecolog칤a, redes sociales), las interacciones son **repetidas** y los agentes pueden aprender. Esto permite que estrategias como el perd칩n (*Tit for Two Tats*) o la tolerancia (*Generous Tit for Tat*) prosperen. Nuestras simulaciones incluyen variantes de m칰ltiples rondas y entornos din치micos para explorar estos matices, ya que, la ignorancia a la dinamica del juego permite entender como se comportan los usuarios, como ejemplo, tendriamos que a la ultima interaccion, nadie copera. lo cual en el mundo real es imposible comprender cuando sera la ultima interaccion entre dos objetos.

---

## 游뱄 Participantes en los Torneos

### Estrategias Cl치sicas
- **Tit for Tat (TFT)**: Cooperar en la primera ronda, luego imitar la jugada anterior del rival.
- **Always Defect (ALLD)**: Traicionar siempre. Efectivo en una sola ronda, pero fracasa en iteraciones.
- **Random**: Elecciones aleatorias. Sirve como "l칤nea base" ca칩tica.
- **Freeman**: Estrategia hipot칠tica que prioriza la reputaci칩n (ej: coopera si el oponente tiene historial cooperativo).

### Nuevos Algoritmos
- **Herencia Gen칠tica**: Estrategias que evolucionan mediante selecci칩n natural (algoritmos gen칠ticos).
- **Orientaci칩n Espacial**: Agentes ubicados en una red (ej: grilla) que solo interact칰an con vecinos, simulando efectos geogr치ficos o sociales.
- **AI-Based Players**: Agentes que usan aprendizaje por refuerzo o redes neuronales para adaptar su estrategia en tiempo real.

A modo de conclusion, quiero generar modelos teoricos concretos que se acerquen poco a poco a las dinamicas sociales presentes en el mundo real, con la finalidad de poder concluir ciertos comportamientos acerca la naturaleza, tanto general como humana.
